{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "515323de-8895-4579-8391-4e291d67f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import various classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d36b2f-c726-408b-91ca-5b86b3f61758",
   "metadata": {},
   "source": [
    "### Reading Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ab726c1-8f66-4fbf-b1b0-4532d130a4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Human</th>\n",
       "      <th>AI</th>\n",
       "      <th>Question_length</th>\n",
       "      <th>Human_length</th>\n",
       "      <th>AI_length</th>\n",
       "      <th>Question_special_count</th>\n",
       "      <th>Human_special_count</th>\n",
       "      <th>AI_special_count</th>\n",
       "      <th>avg_special_char_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1) Write short note about Transition Probabili...</td>\n",
       "      <td>Transition Probability Matrix P is used in Mar...</td>\n",
       "      <td>A transition probability matrix is a mathemati...</td>\n",
       "      <td>56</td>\n",
       "      <td>388</td>\n",
       "      <td>629</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>29.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2) Write short note about Bayes' Rule</td>\n",
       "      <td>P (B|A) = P(A|B)P(B) / P(A)\\n            = P(A...</td>\n",
       "      <td>Bayes' Rule is a fundamental theorem in probab...</td>\n",
       "      <td>37</td>\n",
       "      <td>131</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3) What is the meaning of outcome in probability?</td>\n",
       "      <td>The outcome of probability is the possible res...</td>\n",
       "      <td>In probability, an outcome refers to a specifi...</td>\n",
       "      <td>49</td>\n",
       "      <td>133</td>\n",
       "      <td>610</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4) How do we transform a process to a Markov c...</td>\n",
       "      <td>The state of the system at time t+1 depends on...</td>\n",
       "      <td>Transforming a process into a Markov chain inv...</td>\n",
       "      <td>51</td>\n",
       "      <td>203</td>\n",
       "      <td>1357</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>37.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5) Write short note about Continuous probabili...</td>\n",
       "      <td>A probability distribution in which the random...</td>\n",
       "      <td>A continuous probability distribution is a typ...</td>\n",
       "      <td>63</td>\n",
       "      <td>170</td>\n",
       "      <td>977</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  1) Write short note about Transition Probabili...   \n",
       "1              2) Write short note about Bayes' Rule   \n",
       "2  3) What is the meaning of outcome in probability?   \n",
       "3  4) How do we transform a process to a Markov c...   \n",
       "4  5) Write short note about Continuous probabili...   \n",
       "\n",
       "                                               Human  \\\n",
       "0  Transition Probability Matrix P is used in Mar...   \n",
       "1  P (B|A) = P(A|B)P(B) / P(A)\\n            = P(A...   \n",
       "2  The outcome of probability is the possible res...   \n",
       "3  The state of the system at time t+1 depends on...   \n",
       "4  A probability distribution in which the random...   \n",
       "\n",
       "                                                  AI  Question_length  \\\n",
       "0  A transition probability matrix is a mathemati...               56   \n",
       "1  Bayes' Rule is a fundamental theorem in probab...               37   \n",
       "2  In probability, an outcome refers to a specifi...               49   \n",
       "3  Transforming a process into a Markov chain inv...               51   \n",
       "4  A continuous probability distribution is a typ...               63   \n",
       "\n",
       "   Human_length  AI_length  Question_special_count  Human_special_count  \\\n",
       "0           388        629                       2                   46   \n",
       "1           131        792                       2                   39   \n",
       "2           133        610                       2                    3   \n",
       "3           203       1357                       2                   58   \n",
       "4           170        977                       2                   14   \n",
       "\n",
       "   AI_special_count  avg_special_char_diff  \n",
       "0                 9              29.333333  \n",
       "1                38              24.666667  \n",
       "2                16               9.333333  \n",
       "3                22              37.333333  \n",
       "4                16               9.333333  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_avg = pd.read_csv('aidata_clean_avg.csv')\n",
    "clean_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0f4f4-6e66-490e-94bf-38988de9c980",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e9c11f4-2f61-4267-8836-b736bd1ca5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation and special characters\n",
    "        #text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        # Remove stopwords\n",
    "        #filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "        return \" \".join(tokens)\n",
    "def generic_preprocessing(df):\n",
    "    human = df.drop(columns=['Question', 'AI']).rename(columns={'Human': 'Response'})\n",
    "    human['Is_AI'] = 0\n",
    "    ai = df.drop(columns=['Question', 'Human']).rename(columns={'AI': 'Response'})\n",
    "    ai['Is_AI'] = 1\n",
    "    data = pd.concat([human, ai], ignore_index=True)\n",
    "    # Apply text preprocessing to a text column\n",
    "    data['processed_text'] = data['Response'].apply(preprocess_text)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcd7ec1b-6834-4c3d-b67e-f43a46b5ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed= generic_preprocessing(clean_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e9c0f02-9281-4554-b55f-e9b5effbf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vectorized text data: (3986, 5891)\n"
     ]
    }
   ],
   "source": [
    "'''from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Assume processed['processed_text'] is a pandas Series containing your text data\n",
    "X_text = processed['processed_text']\n",
    "\n",
    "# Fit the vectorizer to the text and transform it into token count vectors\n",
    "X_vectorized = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# X_vectorized is now a sparse matrix of shape (n_samples, n_features)\n",
    "print(\"Shape of vectorized text data:\", X_vectorized.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5402c8b-a32e-4a84-bb95-b21d612cc995",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb5d797f-c630-4572-9f49-f4777599e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3188,) (3188,)\n",
      "Testing set shape: (798,) (798,)\n"
     ]
    }
   ],
   "source": [
    "# 80% 20% split of data\n",
    "X = processed['processed_text']\n",
    "y = processed['Is_AI']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41706a0-21d0-4d72-b055-5dd635ce4fee",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d87f1c1-9da1-4d3d-b404-d255722b24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Logistic Regression Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       416\n",
      "           1       0.86      0.86      0.86       382\n",
      "\n",
      "    accuracy                           0.86       798\n",
      "   macro avg       0.86      0.86      0.86       798\n",
      "weighted avg       0.86      0.86      0.86       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1577\n",
      "           1       0.99      0.97      0.98      1611\n",
      "\n",
      "    accuracy                           0.98      3188\n",
      "   macro avg       0.98      0.98      0.98      3188\n",
      "weighted avg       0.98      0.98      0.98      3188\n",
      "\n",
      "========================================\n",
      "Naive Bayes Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81       416\n",
      "           1       0.76      0.93      0.84       382\n",
      "\n",
      "    accuracy                           0.83       798\n",
      "   macro avg       0.84      0.83      0.83       798\n",
      "weighted avg       0.84      0.83      0.82       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86      1577\n",
      "           1       0.83      0.94      0.88      1611\n",
      "\n",
      "    accuracy                           0.87      3188\n",
      "   macro avg       0.88      0.87      0.87      3188\n",
      "weighted avg       0.88      0.87      0.87      3188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roshn\\anaconda3\\envs\\ai_detector\\lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "SVM Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       416\n",
      "           1       0.82      0.85      0.83       382\n",
      "\n",
      "    accuracy                           0.84       798\n",
      "   macro avg       0.84      0.84      0.84       798\n",
      "weighted avg       0.84      0.84      0.84       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1577\n",
      "           1       1.00      1.00      1.00      1611\n",
      "\n",
      "    accuracy                           1.00      3188\n",
      "   macro avg       1.00      1.00      1.00      3188\n",
      "weighted avg       1.00      1.00      1.00      3188\n",
      "\n",
      "========================================\n",
      "Decision Tree Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       416\n",
      "           1       0.72      0.76      0.74       382\n",
      "\n",
      "    accuracy                           0.74       798\n",
      "   macro avg       0.74      0.74      0.74       798\n",
      "weighted avg       0.74      0.74      0.74       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1577\n",
      "           1       1.00      1.00      1.00      1611\n",
      "\n",
      "    accuracy                           1.00      3188\n",
      "   macro avg       1.00      1.00      1.00      3188\n",
      "weighted avg       1.00      1.00      1.00      3188\n",
      "\n",
      "========================================\n",
      "Random Forest Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       416\n",
      "           1       0.82      0.82      0.82       382\n",
      "\n",
      "    accuracy                           0.83       798\n",
      "   macro avg       0.83      0.83      0.83       798\n",
      "weighted avg       0.83      0.83      0.83       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1577\n",
      "           1       1.00      1.00      1.00      1611\n",
      "\n",
      "    accuracy                           1.00      3188\n",
      "   macro avg       1.00      1.00      1.00      3188\n",
      "weighted avg       1.00      1.00      1.00      3188\n",
      "\n",
      "========================================\n",
      "Gradient Boosting Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       416\n",
      "           1       0.85      0.77      0.81       382\n",
      "\n",
      "    accuracy                           0.83       798\n",
      "   macro avg       0.83      0.82      0.82       798\n",
      "weighted avg       0.83      0.83      0.83       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1577\n",
      "           1       0.89      0.81      0.85      1611\n",
      "\n",
      "    accuracy                           0.86      3188\n",
      "   macro avg       0.86      0.86      0.86      3188\n",
      "weighted avg       0.86      0.86      0.86      3188\n",
      "\n",
      "========================================\n",
      "K-Nearest Neighbors Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74       416\n",
      "           1       0.70      0.79      0.75       382\n",
      "\n",
      "    accuracy                           0.74       798\n",
      "   macro avg       0.74      0.74      0.74       798\n",
      "weighted avg       0.75      0.74      0.74       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82      1577\n",
      "           1       0.79      0.90      0.84      1611\n",
      "\n",
      "    accuracy                           0.83      3188\n",
      "   macro avg       0.84      0.83      0.83      3188\n",
      "weighted avg       0.84      0.83      0.83      3188\n",
      "\n",
      "========================================\n",
      "Neural Network Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       416\n",
      "           1       0.83      0.87      0.85       382\n",
      "\n",
      "    accuracy                           0.85       798\n",
      "   macro avg       0.85      0.86      0.85       798\n",
      "weighted avg       0.86      0.85      0.85       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1577\n",
      "           1       1.00      1.00      1.00      1611\n",
      "\n",
      "    accuracy                           1.00      3188\n",
      "   macro avg       1.00      1.00      1.00      3188\n",
      "weighted avg       1.00      1.00      1.00      3188\n",
      "\n",
      "========================================\n",
      "MLPClassifier Classification Report:\n",
      "----------\n",
      "Test Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       416\n",
      "           1       0.82      0.88      0.85       382\n",
      "\n",
      "    accuracy                           0.85       798\n",
      "   macro avg       0.85      0.85      0.85       798\n",
      "weighted avg       0.85      0.85      0.85       798\n",
      "\n",
      "----------\n",
      "Train Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1577\n",
      "           1       1.00      1.00      1.00      1611\n",
      "\n",
      "    accuracy                           1.00      3188\n",
      "   macro avg       1.00      1.00      1.00      3188\n",
      "weighted avg       1.00      1.00      1.00      3188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a dictionary of classification models\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear'),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': LinearSVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=300),\n",
    "    'MLPClassifier' : MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through models, build pipelines and evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),  # Tokenize and vectorize text\n",
    "        ('clf', clf)                  # classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    train_pred= pipeline.predict(X_train)\n",
    "    \n",
    "    # Generate and print the classification report for the current model\n",
    "    report = classification_report(y_test, predictions)\n",
    "    tain_report = classification_report(y_train, train_pred)\n",
    "    print(\"=\"*40)\n",
    "    print(f\"{name} Classification Report:\")\n",
    "    print(\"-\"*10)\n",
    "    print(\"Test Report\")\n",
    "    print(report)\n",
    "    print(\"-\"*10)\n",
    "    print(\"Train Report\")\n",
    "    print(tain_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921153e8-a44f-4387-bb2f-36bf1a753a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Tensor flow & BERT (to be explored)\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# --- 3. Tokenize and Pad Sequences ---\n",
    "# You can adjust num_words to control the vocabulary size.\n",
    "num_words = 5000\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True)\n",
    "tokenizer.fit_on_texts(X_text)\n",
    "X_seq = tokenizer.texts_to_sequences(X_text)\n",
    "\n",
    "# Determine the maximum sequence length (or specify a fixed value)\n",
    "max_length = max(len(seq) for seq in X_seq)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# --- 4. Train-Test Split (80/20) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 5. Build the Keras Model ---\n",
    "# The Embedding layer converts integer sequences into dense vectors.\n",
    "# GlobalAveragePooling1D is used to aggregate the sequence information.\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=50, input_length=max_length))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- 6. Train the Model ---\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# --- 7. Evaluate the Model ---\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy (Keras Model):\", accuracy)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
